{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.stats as ss\n",
    "\n",
    "import sklearn.model_selection as ms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata = []\\nf = open('covtype.data','r')\\nwhile(1):\\n    line = f.readline()\\n    if  len(line) < 100:\\n        print line\\n    \\n    if len(line) == 0: break\\n    data.append(np.array([float(k) for k in line.split(',')]))\\n    if len(data) % 100000 == 0:\\n        print len(data)\\n        \\nf.close\\ndata = np.vstack(data)\\nN = data.shape[0]\\nidx = np.random.permutation(N)\\n\\n\\nX_test = data[:N/5,:]\\nX_train = data[N/5:,:]\\ny_test = X_test[:,-1]\\ny_train = X_train[:,-1]\\nX_test = X_test[:,:-1]\\nX_train = X_train[:,:-1]\\n\\n\\nsio.savemat('covtype.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\\n\\ndata = sio.loadmat('covtype.mat')\\nX_train = data['X_train']\\nX_test = data['X_test']\\ny_train = data['y_train'][0]\\ny_test = data['y_test'][0]\\n\\ny_idx_train = [np.where(np.equal(y_train,k))[0] for k in np.unique(y_train)]\\n\\nfor i in xrange(len(y_idx_train)):\\n    y_idx = y_idx_train[i]\\n    y_idx_train[i] = y_idx[np.random.choice(len(y_idx),len(y_idx)/1000+1,replace=False)]\\n    \\ny_idx_train = np.hstack(y_idx_train)\\ny_idx_train = np.random.permutation(y_idx_train)\\n\\nX_train = X_train[y_idx_train,:]\\ny_train = y_train[y_idx_train]\\n\\nsio.savemat('covtype_reduced.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\\n\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load your data (don't touch, just run)\n",
    "\"\"\"\n",
    "data = []\n",
    "f = open('covtype.data','r')\n",
    "while(1):\n",
    "    line = f.readline()\n",
    "    if  len(line) < 100:\n",
    "        print line\n",
    "    \n",
    "    if len(line) == 0: break\n",
    "    data.append(np.array([float(k) for k in line.split(',')]))\n",
    "    if len(data) % 100000 == 0:\n",
    "        print len(data)\n",
    "        \n",
    "f.close\n",
    "data = np.vstack(data)\n",
    "N = data.shape[0]\n",
    "idx = np.random.permutation(N)\n",
    "\n",
    "\n",
    "X_test = data[:N/5,:]\n",
    "X_train = data[N/5:,:]\n",
    "y_test = X_test[:,-1]\n",
    "y_train = X_train[:,-1]\n",
    "X_test = X_test[:,:-1]\n",
    "X_train = X_train[:,:-1]\n",
    "\n",
    "\n",
    "sio.savemat('covtype.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\n",
    "\n",
    "data = sio.loadmat('covtype.mat')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train'][0]\n",
    "y_test = data['y_test'][0]\n",
    "\n",
    "y_idx_train = [np.where(np.equal(y_train,k))[0] for k in np.unique(y_train)]\n",
    "\n",
    "for i in xrange(len(y_idx_train)):\n",
    "    y_idx = y_idx_train[i]\n",
    "    y_idx_train[i] = y_idx[np.random.choice(len(y_idx),len(y_idx)/1000+1,replace=False)]\n",
    "    \n",
    "y_idx_train = np.hstack(y_idx_train)\n",
    "y_idx_train = np.random.permutation(y_idx_train)\n",
    "\n",
    "X_train = X_train[y_idx_train,:]\n",
    "y_train = y_train[y_idx_train]\n",
    "\n",
    "sio.savemat('covtype_reduced.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7.] [1. 2. 3. 4. 5. 6. 7.]\n",
      "(468, 54) (116202, 54) (468,) (116202,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = sio.loadmat('covtype_reduced.mat')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train'][0]\n",
    "y_test = data['y_test'][0]\n",
    "\n",
    "print(np.unique(y_train), np.unique(y_test))\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy =  3.3141823231610834\n",
      "conditional entropy =  3.3029598816135173\n"
     ]
    }
   ],
   "source": [
    "def pr_xlog2pr_x(pr_x):\n",
    "    if(pr_x == 0):\n",
    "        return 0\n",
    "    return -1*pr_x*np.log2(pr_x)\n",
    "\n",
    "def entropy_array(label):\n",
    "    #     print(label)\n",
    "    \n",
    "    counts = np.unique(label, return_counts=True)[1]\n",
    "#     print(counts)\n",
    "    prob_x = counts / len(label)\n",
    "#     print(prob_x)\n",
    "    \n",
    "    calc_pr_x_log2_pr_x = np.vectorize(pr_xlog2pr_x)\n",
    "    \n",
    "    pr_x_log2_pr_x = calc_pr_x_log2_pr_x(prob_x)\n",
    "#     print(pr_x_log2_pr_x)\n",
    "    return pr_x_log2_pr_x\n",
    "\n",
    "def entropy(label):\n",
    "\n",
    "    \n",
    "    entropy = np.sum(entropy_array(label))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def pr_xylog2pr_x_given_y(pr_xy, pr_x_given_y):\n",
    "    if(pr_x_given_y == 0):\n",
    "        return 0\n",
    "    return -1*pr_xy*np.log2(pr_x_given_y)\n",
    "\n",
    "def cond_entropy_array(label, split):\n",
    "    x_uniques = np.unique(label, return_counts=True)\n",
    "    x_counts = x_uniques[1]\n",
    "    prob_x = x_counts / len(label)\n",
    "    \n",
    "    y_uniques = np.unique(split, return_counts=True)\n",
    "    y_counts = y_uniques[1]\n",
    "    prob_y = y_counts / len(split)\n",
    "    \n",
    "    prob_x_and_y = np.zeros((len(x_uniques[0]),len(y_uniques[0])))\n",
    "    prob_x_given_y = np.zeros((len(x_uniques[0]),len(y_uniques[0])))\n",
    "    pr_xy_log2_pr_x_given = np.zeros((len(x_uniques[0]),len(y_uniques[0])))\n",
    "    \n",
    "    for x_index, x in enumerate(x_uniques[0]):\n",
    "        get_all_x = (label == x)\n",
    "        for y_index, y in enumerate(y_uniques[0]):\n",
    "            get_all_y = (split == y)\n",
    "            get_x_and_y = np.logical_and(get_all_x, get_all_y)\n",
    "            x_and_y_counts = np.count_nonzero(get_x_and_y)\n",
    "            prob_x_and_y[x_index][y_index] = x_and_y_counts / len(label)\n",
    "            prob_x_given_y[x_index][y_index] = prob_x_and_y[x_index][y_index] / prob_y[y_index]\n",
    "            pr_xy_log2_pr_x_given[x_index][y_index] = pr_xylog2pr_x_given_y(prob_x_and_y[x_index][y_index], prob_x_given_y[x_index][y_index])\n",
    "    \n",
    "#     print(prob_x_and_y)\n",
    "#     print(prob_x_given_y)\n",
    "#     print(pr_xy_log2_pr_x_given)\n",
    "    \n",
    "    return pr_xy_log2_pr_x_given\n",
    "\n",
    "def cond_entropy(label,split):\n",
    "    \n",
    "    conditional_entropy = np.sum(cond_entropy_array(label, split))\n",
    "    \n",
    "    return conditional_entropy\n",
    "\n",
    "random_sequences = sio.loadmat('random_sequences.mat')\n",
    "\n",
    "s1 = random_sequences['s1'][0]\n",
    "s2 = random_sequences['s2'][0]\n",
    "\n",
    "print('entropy = ', entropy(s1))\n",
    "print('conditional entropy = ', cond_entropy(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 54)\n",
      "split feature: 0\n",
      "split value: 2843\n",
      "information gained in first step 0.34265604135138417\n"
     ]
    }
   ],
   "source": [
    "def find_best_split(x,y):\n",
    "#     print(x.T)\n",
    "#     print(y)\n",
    "    best_feat = 0\n",
    "    splitval = 0.\n",
    "    set1 = range(int(len(y)/2))\n",
    "    set2 = range(int(len(y)/2),len(y))\n",
    "    \n",
    "#     max_ig = 0\n",
    "#     best_feat = 0\n",
    "#     split_val = 0\n",
    "#     for index, feat in enumerate(x.T): \n",
    "# #         print(index)\n",
    "#         h_y = entropy_array(y)\n",
    "# #         print(h_y)\n",
    "#         h_y_given_x = cond_entropy_array(y,feat)\n",
    "\n",
    "#         x_uniques = np.unique(feat, return_counts=True)[0]\n",
    "\n",
    "        \n",
    "#         cond_entropies = np.sum(h_y_given_x, axis=1)\n",
    "# #         print(cond_entropies)\n",
    "#         igs = h_y - cond_entropies\n",
    "# #         print(igs)\n",
    "        \n",
    "#         max_ig_local = max(igs)\n",
    "#         max_ig_local_index = np.argmax(igs)\n",
    "# #         print(max_ig_local, max_ig_local_index)\n",
    "#         if(max_ig_local > max_ig):\n",
    "#             max_ig = max_ig_local\n",
    "#             best_feat = index\n",
    "#     var = x.T[best_feat]\n",
    "#     var = set(var)\n",
    "    \n",
    "    \n",
    "#     ordered_uniques = sorted(var)\n",
    "# #     print(ordered_uniques)\n",
    "#     max_ig = 0\n",
    "#     for i in range(0, int(max(x.T[best_feat])), 10):\n",
    "#         indices = np.where(x.T[best_feat]>i)\n",
    "#         if(len(y[indices]) > 0):\n",
    "#             h_y = entropy_array(y[indices])\n",
    "#             h_y_given_x = cond_entropy_array(y[indices], x.T[best_feat, indices])\n",
    "#     #         print(h_y)\n",
    "#     #         print(h_y_given_x)\n",
    "#             h_y_given_x = np.sum(h_y_given_x,axis=1)\n",
    "#             ig = h_y-h_y_given_x\n",
    "#     #         print(ig)\n",
    "#             max_ig_local = np.argmax(ig)\n",
    "#             if(max_ig_local > max_ig):\n",
    "#                 max_ig = max_ig_local\n",
    "#                 splitval = i\n",
    "        \n",
    "        \n",
    "        \n",
    "    max_ig = 0\n",
    "    best_feat = 0\n",
    "    splitval = 1\n",
    "    print(x.shape)\n",
    "    for index, f in enumerate(x.T):\n",
    "        for val in range(max(1,int(min(f))), int(max(f))):\n",
    "            \n",
    "            split = f > val\n",
    "            split = np.where(split)[0]\n",
    "            split2 = f<=val\n",
    "            split2 = np.where(split2)[0]\n",
    "            h_s = entropy(y)\n",
    "            h_sl = entropy(y[split])\n",
    "            h_sr = entropy(y[split2])\n",
    "            h_s_given_split = ((len(split)/len(y))*h_sl) + ((len(split2)/len(y))*h_sr)\n",
    "            ig = h_s - h_s_given_split\n",
    "            if(ig>max_ig):\n",
    "                max_ig = ig\n",
    "                best_feat = index\n",
    "                splitval = val\n",
    "        \n",
    "        \n",
    "        \n",
    "#     print(splitval)\n",
    "#         print()\n",
    "#         local_max_ig = 0\n",
    "#         local_max_ig_x = 0\n",
    "#         for y_index in range(len(h_y_given_x)):\n",
    "#             for x_index in range(len(h_y_given_x[0])):\n",
    "#                 ig = h_y[y_index] - h_y_given_x[y_index][x_index]\n",
    "                \n",
    "#                 if(ig > local_max_ig):\n",
    "#                     local_max_ig = max(local_max_ig, ig)\n",
    "#                     local_max_ig_x = x_uniques[x_index]\n",
    "#         print(min(feat))\n",
    "                \n",
    "#         if(local_max_ig > max_ig):\n",
    "#             max_ig = local_max_ig\n",
    "#             best_feat = index\n",
    "#             splitval = local_max_ig_x\n",
    "#     print(best_feat, x.T[best_feat])\n",
    "            \n",
    "#     print(best_feat)\n",
    "#     print(x[:, best_feat])\n",
    "#     print(splitval)\n",
    "    arr = x[:,best_feat]\n",
    "#     print(arr)\n",
    "    set1 = arr > splitval\n",
    "    set1 = np.where(set1)[0]\n",
    "    \n",
    "    set2 = arr <= splitval\n",
    "    set2 = np.where(set2)[0]\n",
    "#     print(set1)\n",
    "    return best_feat, splitval, set1, set2\n",
    "\n",
    "\n",
    "best_feat, splitval, set1, set2 = find_best_split(X_train, y_train)\n",
    "print(\"split feature:\", best_feat)\n",
    "print(\"split value:\", splitval)\n",
    "y_new = y_train * 0\n",
    "y_new[set1] = 1\n",
    "print('information gained in first step', entropy(y_train) - cond_entropy(y_train,y_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity(y): #split next node based on most purity\n",
    "    return ss.mode(y)[1]/len(y+0.)\n",
    "    \n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,  sample_idx, nodeid,  is_leaf = True):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.id = nodeid\n",
    "        self.sample_idx = sample_idx\n",
    "        self.children = []\n",
    "        \n",
    "        \n",
    "        \n",
    "    def visit_node(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.label\n",
    "        \"\"\" Fill me in (x is list of features, check node and see feature and split value to decide to go to left or right node) \"\"\" \n",
    "        if(x[self.splitfeat] > splitval):\n",
    "        #         print(x)\n",
    "            return self.children[0].visit_node(x)\n",
    "        else: \n",
    "            return self.children[1].visit_node(x)\n",
    "        \n",
    "    def add_split_details(self, splitfeat, splitval)  :\n",
    "        self.splitfeat = splitfeat\n",
    "        self.splitval = splitval\n",
    "    \n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self, x,y):\n",
    "        m = len(y)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.maxid = -1\n",
    "        self.root = self.construct_node(np.array(range(m)))\n",
    "        self.leaves = [self.root]\n",
    "        \n",
    "    def print_tree(self):\n",
    "        print('printing tree...')\n",
    "        def print_node(parent, node):\n",
    "            print(node.id, end='')\n",
    "            \n",
    "            if parent is not None:\n",
    "                print(', parent ', parent.id,end='')\n",
    "            else:\n",
    "                print(', ROOT',end='')\n",
    "                \n",
    "            print(', label ', node.label, end='')\n",
    "            if node.is_leaf: \n",
    "                print(', LEAF, ', 'nsamples %d, purity %.2f' %(len(node.sample_idx), purity(self.y[node.sample_idx])))\n",
    "            else:\n",
    "                print(', NONLEAF, split %d, val %.2f' % (node.splitfeat, node.splitval))\n",
    "            if not node.is_leaf:\n",
    "                for ch in node.children:\n",
    "                    print_node(node, ch)\n",
    "        print_node(None, self.root)\n",
    "        \n",
    "        \n",
    "    def construct_node(self, sample_idx):\n",
    "#         print(self.y[sample_idx])\n",
    "        node = Node(sample_idx, self.maxid + 1,  True)\n",
    "        node.label = round(np.mean(self.y[sample_idx]))#fill me in\n",
    "        node.entropy = entropy(self.y[sample_idx])\n",
    "        node.num_mistakes = np.sum(np.not_equal(node.label, self.y[sample_idx]))\n",
    "        self.maxid += 1\n",
    "        return node\n",
    "        \n",
    "\n",
    "\n",
    "    def report_train_err(self):\n",
    "        total_mistakes = 0\n",
    "        for leaf in self.leaves:\n",
    "            total_mistakes += leaf.num_mistakes\n",
    "        return total_mistakes / (len(self.y)+0.)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.root.visit_node(x)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing tree...\n",
      "0, ROOT, label  2, LEAF,  nsamples 468, purity 0.44\n",
      "current train err: 0.5641025641025641\n",
      "current test err: 0.3138069912738163\n",
      "(468, 54)\n",
      "printing tree...\n",
      "0, ROOT, label  2, NONLEAF, split 0, val 2843.00\n",
      "1, parent  0, label  1, LEAF,  nsamples 352, purity 0.51\n",
      "2, parent  0, label  2, LEAF,  nsamples 116, purity 0.46\n",
      "one step train err: 0.5021367521367521\n",
      "one step test err: 0.4959983477048588\n",
      "splitting node: 2\n",
      "(116, 54)\n",
      "0 step train err: 0.49145299145299143\n",
      "0 step test err: 0.7755288205022289\n",
      "splitting node: 3\n",
      "(79, 54)\n",
      "1 step train err: 0.4829059829059829\n",
      "1 step test err: 0.38671451438013116\n",
      "splitting node: 6\n",
      "(21, 54)\n",
      "2 step train err: 0.47649572649572647\n",
      "2 step test err: 0.7846250494827972\n",
      "splitting node: 1\n",
      "(352, 54)\n",
      "3 step train err: 0.5341880341880342\n",
      "3 step test err: 0.3138069912738163\n",
      "splitting node: 10\n",
      "(220, 54)\n",
      "4 step train err: 0.5149572649572649\n",
      "4 step test err: 0.3138069912738163\n",
      "splitting node: 9\n",
      "(132, 54)\n",
      "5 step train err: 0.5170940170940171\n",
      "5 step test err: 0.24971170892067263\n",
      "splitting node: 13\n",
      "(69, 54)\n",
      "6 step train err: 0.5042735042735043\n",
      "6 step test err: 0.6592657613466205\n",
      "splitting node: 14\n",
      "(63, 54)\n",
      "7 step train err: 0.4935897435897436\n",
      "7 step test err: 0.38184368599507756\n",
      "splitting node: 11\n",
      "(167, 54)\n",
      "8 step train err: 0.4807692307692308\n",
      "8 step test err: 0.3517237224832619\n",
      "splitting node: 19\n",
      "(101, 54)\n",
      "9 step train err: 0.4658119658119658\n",
      "9 step test err: 0.452289977797284\n",
      "splitting node: 18\n",
      "(17, 54)\n",
      "10 step train err: 0.4594017094017094\n",
      "10 step test err: 0.7846250494827972\n",
      "splitting node: 24\n",
      "(2, 54)\n",
      "11 step train err: 0.45726495726495725\n",
      "11 step test err: 0.7845820209634946\n",
      "splitting node: 12\n",
      "(53, 54)\n",
      "12 step train err: 0.44871794871794873\n",
      "12 step test err: 0.5921498769384348\n",
      "splitting node: 4\n",
      "(37, 54)\n",
      "13 step train err: 0.45085470085470086\n",
      "13 step test err: 0.7846250494827972\n",
      "splitting node: 30\n",
      "(9, 54)\n",
      "14 step train err: 0.44871794871794873\n",
      "14 step test err: 0.7846250494827972\n",
      "splitting node: 32\n",
      "(6, 54)\n",
      "15 step train err: 0.44871794871794873\n",
      "15 step test err: 0.7846250494827972\n",
      "splitting node: 33\n",
      "(3, 54)\n",
      "16 step train err: 0.4465811965811966\n",
      "16 step test err: 0.7846250494827972\n",
      "splitting node: 34\n",
      "(3, 54)\n",
      "17 step train err: 0.4444444444444444\n",
      "17 step test err: 0.7752706493864133\n",
      "splitting node: 35\n",
      "(2, 54)\n",
      "18 step train err: 0.4423076923076923\n",
      "18 step test err: 0.7752706493864133\n",
      "splitting node: 37\n",
      "(2, 54)\n",
      "19 step train err: 0.44017094017094016\n",
      "19 step test err: 0.7694445878728421\n",
      "splitting node: 15\n",
      "(58, 54)\n",
      "20 step train err: 0.4337606837606838\n",
      "20 step test err: 0.767568544431249\n",
      "splitting node: 44\n",
      "(10, 54)\n",
      "21 step train err: 0.4337606837606838\n",
      "21 step test err: 0.8128603638491593\n",
      "splitting node: 46\n",
      "(5, 54)\n",
      "22 step train err: 0.4337606837606838\n",
      "22 step test err: 0.7742982048501746\n",
      "splitting node: 47\n",
      "(3, 54)\n",
      "23 step train err: 0.43162393162393164\n",
      "23 step test err: 0.767568544431249\n",
      "printing tree...\n",
      "0, ROOT, label  2, NONLEAF, split 0, val 2843.00\n",
      "1, parent  0, label  1, NONLEAF, split 0, val 3170.00\n",
      "9, parent  1, label  2, NONLEAF, split 0, val 3042.00\n",
      "13, parent  9, label  1, NONLEAF, split 0, val 2685.00\n",
      "15, parent  13, label  1, NONLEAF, split 0, val 2685.00\n",
      "43, parent  15, label  1, LEAF,  nsamples 48, purity 0.58\n",
      "44, parent  15, label  1, NONLEAF, split 0, val 3131.00\n",
      "45, parent  44, label  1, LEAF,  nsamples 5, purity 0.60\n",
      "46, parent  44, label  1, NONLEAF, split 0, val 2434.00\n",
      "47, parent  46, label  1, NONLEAF, split 0, val 2685.00\n",
      "49, parent  47, label  3, LEAF,  nsamples 2, purity 0.50\n",
      "50, parent  47, label  1, LEAF,  nsamples 1, purity 1.00\n",
      "48, parent  46, label  2, LEAF,  nsamples 2, purity 0.50\n",
      "16, parent  13, label  1, LEAF,  nsamples 11, purity 0.55\n",
      "14, parent  9, label  2, NONLEAF, split 0, val 2936.00\n",
      "17, parent  14, label  1, LEAF,  nsamples 46, purity 0.54\n",
      "18, parent  14, label  1, NONLEAF, split 9, val 319.00\n",
      "23, parent  18, label  1, LEAF,  nsamples 15, purity 0.67\n",
      "24, parent  18, label  1, NONLEAF, split 0, val 2410.00\n",
      "25, parent  24, label  5, LEAF,  nsamples 1, purity 1.00\n",
      "26, parent  24, label  3, LEAF,  nsamples 1, purity 1.00\n",
      "10, parent  1, label  1, NONLEAF, split 0, val 2877.00\n",
      "11, parent  10, label  2, NONLEAF, split 0, val 2954.00\n",
      "19, parent  11, label  1, NONLEAF, split 0, val 2885.00\n",
      "21, parent  19, label  1, LEAF,  nsamples 79, purity 0.52\n",
      "22, parent  19, label  2, LEAF,  nsamples 22, purity 0.59\n",
      "20, parent  11, label  2, LEAF,  nsamples 66, purity 0.53\n",
      "12, parent  10, label  1, NONLEAF, split 0, val 2744.00\n",
      "27, parent  12, label  1, LEAF,  nsamples 47, purity 0.57\n",
      "28, parent  12, label  1, LEAF,  nsamples 6, purity 0.67\n",
      "2, parent  0, label  2, NONLEAF, split 0, val 2524.00\n",
      "3, parent  2, label  1, NONLEAF, split 0, val 2934.00\n",
      "5, parent  3, label  1, LEAF,  nsamples 58, purity 0.57\n",
      "6, parent  3, label  2, NONLEAF, split 3, val 228.00\n",
      "7, parent  6, label  1, LEAF,  nsamples 11, purity 0.64\n",
      "8, parent  6, label  1, LEAF,  nsamples 10, purity 0.60\n",
      "4, parent  2, label  2, NONLEAF, split 9, val 726.00\n",
      "29, parent  4, label  1, LEAF,  nsamples 28, purity 0.54\n",
      "30, parent  4, label  1, NONLEAF, split 1, val 174.00\n",
      "31, parent  30, label  1, LEAF,  nsamples 3, purity 0.67\n",
      "32, parent  30, label  1, NONLEAF, split 0, val 2685.00\n",
      "33, parent  32, label  1, NONLEAF, split 0, val 2685.00\n",
      "35, parent  33, label  1, NONLEAF, split 0, val 2410.00\n",
      "39, parent  35, label  5, LEAF,  nsamples 1, purity 1.00\n",
      "40, parent  35, label  3, LEAF,  nsamples 1, purity 1.00\n",
      "36, parent  33, label  5, LEAF,  nsamples 1, purity 1.00\n",
      "34, parent  32, label  1, NONLEAF, split 0, val 2410.00\n",
      "37, parent  34, label  1, NONLEAF, split 0, val 2739.00\n",
      "41, parent  37, label  5, LEAF,  nsamples 1, purity 1.00\n",
      "42, parent  37, label  3, LEAF,  nsamples 1, purity 1.00\n",
      "38, parent  34, label  3, LEAF,  nsamples 1, purity 1.00\n",
      "25 step train err: 0.43162393162393164\n",
      "25 step test err: 0.767568544431249\n"
     ]
    }
   ],
   "source": [
    "def get_test_err(tree):\n",
    "    # get test error\n",
    "    num_test_mistakes = 0\n",
    "    for k in range(len(y_test)):\n",
    "#     for k in range(1):\n",
    "        x,y = X_test[k,:],y_test[k]\n",
    "#         print(x)\n",
    "        if y != tree.predict(x):\n",
    "            num_test_mistakes += 1\n",
    "    return num_test_mistakes / (len(y_test)+0.)\n",
    "\n",
    "\n",
    "\n",
    "tree = Tree(X_train,y_train)\n",
    "tree.print_tree()\n",
    "print('current train err:', tree.report_train_err())\n",
    "print('current test err:', get_test_err(tree))\n",
    "\n",
    "\n",
    "# my first split\n",
    "best_feat, splitval, set1, set2 = find_best_split(X_train, y_train)\n",
    " \n",
    "left_child = tree.construct_node(set1)\n",
    "right_child = tree.construct_node(set2)\n",
    "tree.root.is_leaf = False\n",
    "tree.leaves.pop(tree.leaves.index(tree.root))\n",
    "tree.root.add_split_details(splitfeat = best_feat, splitval = splitval)\n",
    "\n",
    "\n",
    "tree.root.children = [left_child, right_child]\n",
    "tree.leaves.extend(tree.root.children)\n",
    "tree.print_tree()\n",
    "print('one step train err:', tree.report_train_err())\n",
    "print('one step test err:', get_test_err(tree))\n",
    "\n",
    "for i in range(24):\n",
    "# while True:\n",
    "    min_purity = float('inf')\n",
    "    best_leaf= tree.leaves[0]\n",
    "#     print(tree.y)\n",
    "    \n",
    "    for leaf in tree.leaves:\n",
    "#         print(leaf.sample_idx)\n",
    "        purityval = purity(tree.y[leaf.sample_idx])\n",
    "#         print(min_purity)\n",
    "\n",
    "        if(purityval < min_purity ):\n",
    "            min_purity = purityval\n",
    "            best_leaf = leaf\n",
    "    if(min_purity == 1):\n",
    "        break\n",
    "    print(\"splitting node:\", best_leaf.id)\n",
    "    best_feat, splitval, set1, set2 = find_best_split(tree.x[best_leaf.sample_idx], y_train[best_leaf.sample_idx])\n",
    "    left_child = tree.construct_node(set1)\n",
    "    right_child = tree.construct_node(set2)\n",
    "    best_leaf.is_leaf = False\n",
    "    tree.leaves.pop(tree.leaves.index(best_leaf))\n",
    "#     print(tree.leaves)\n",
    "    best_leaf.add_split_details(splitfeat = best_feat, splitval = splitval)\n",
    "    \n",
    "    best_leaf.children = [left_child, right_child]\n",
    "    tree.leaves.extend(best_leaf.children)\n",
    "    string=\"\"\n",
    "    for leaf in tree.leaves:\n",
    "        string += str(leaf.id) +\", \"\n",
    "    print(i,'step train err:', tree.report_train_err())\n",
    "    print(i, 'step test err:', get_test_err(tree))\n",
    "#     print(string)\n",
    "tree.print_tree()\n",
    "print('25 step train err:', tree.report_train_err())\n",
    "print('25 step test err:', get_test_err(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
